---
output:
  pdf_document: default
  html_document: default
---
# Data Futures

## Andrew: On Visualisations

### True Value and Purpose of Visualisations

To consider trends in visualisation let's begin by identifying the core value of data visualisation - what does it do? In general terms we think about things using language but we understand things using imagery. Our memories work better when we link items to images (even unrelated images) as evidenced by many mnemonic tools.

Data visualisation is the process of presenting information using means other than language as the principal conduit for transfer of meaning/understanding/knowledge. If we think about our senses, 3 of the 5 (touch, smell, taste) are principally involved with our situational awareness. Hearing and sight, whilst obviously having key situational awareness roles, are our principal sources of knowledge awareness/learning at a higher cognitive level. Higher level information that we receive verbally is principally delivered via language - yes we could be learning about sounds themselves in which case there is a combination of non-verbal and verbal but when attending lectures or at work listening to the boss the language is important - doubtless we are also processing a ton of non-verbal messages at work too. At uni and at work our non-situational visible inputs are often computer screens or paper - what Edward Tufte refers to as "flatland".

So now consider what we look at in flatland - a lot of words and numbers which require processing via our brain's language centres (Wernicke's area, Angular Gyrus, Insular Cortex, etc.) before they can be understood. That understanding is very often visual, do you **see** what I mean? Data visualisations cut out the language middle-man and, because they are not constrained by the bandwidth of our language processing systems, provide a high-speed information channel capable of carrying lots of data very quickly into the "understanding" part of the brain. Language is an incredibly powerful brain function. It is arguably that which lifts humans above other species, more even than opposable thumbs, but it is slow to process compared to image processing - we have been finding meaning in what we see for a lot longer than we have been translating meaning into and out of language.

All this is by way of suggesting that the purpose of data visualisation is to provide a means to convey understanding/knowledge without the use of language. In practice, of course, language is often used to augment/enhance visualisations (scales, labels, titles, explanatory notes) but in many cases the data is just way too dense to be conveyed in any other manner than a visualisation (think picture, thousand words) as evidenced by the most common, oldest and data dense visualisations we have - maps.

```{r echo=FALSE, fig.cap="School map of the Canton of Zurich 1:150 000, Eduard Imhof and collaborator"}
knitr::include_graphics("Images/Imhof.jpg", dpi = NA)
```

### The Effective Use of Visualisations

This chapter is heavily influenced (as many discussions of visualisation are) by the works of Edward Tufte, the Yoda of data visualisation. Yoda is an appropriate term because his approach is to use many examples of good and bad data visualisation practice and his objective appears to be to guide and advise by providing clarity as to why certain visualisations are easier to understand. He advocates concepts such as:

- minimise use of non-data ink
- remove chartjunk
- avoid harsh palettes
- its okay to have high data density

Perhaps because of the clarity and almost pervasive uptake of Tufte's guidelines/advice, we are beginning to see more appropriate (gentler) palettes being offered as default colour schemes and more awareness of perception issues (e.g. Moirè effect) in business intelligence tools such as Tableau and Sisense.

```{r echo=FALSE, fig.cap="Moirè Effect - Vibrations in the Image", out.width="60%"}
knitr::include_graphics("Images/moire.png", dpi = NA)
```

Before diving into trends and fads though, pause to consider and remember that the objective of data visualisations should be to transfer knowledge and understanding via images rather than words. If we understand things ourselves in a visual way and want to transfer that understanding to our reader then we can most simply do that by presenting that information visually. 

Are you beginning to understand why all those styles of the 90's with Moirè effects were so bad?

The effective use of a visualisation to transfer knowledge or information, however, assumes there is knowledge/understanding on the part of the author in the first place. As we turn to tools, technologies, trends and fads consider the risks associated with any mechanism that makes it easier to deliver "information" about data (especially big data) even if the "author" doesn't understand the data themselves.

### Tools, Technologies, Trends and Fads

The first, and possibly most significant, trend of data visualisation is the need for it. Big data is presenting a challenge. A lot of information is being gathered and supporting a conclusion or recommendation based on big data often requires some form of supporting encapsulation/presentation of that information. Overly simplifying large volumes of data risks losing the message behind the detail so visualisation is becoming a more important tool. The volume and depth of data, the need to present multivariate analyses, the complexity of the messages all can be addressed by powerful, well-structured data visualisations.

#### How Big is Yours?

In 1990 Tufte mused on:

> the essential dilemma of a computer display: at every screen there are two powerful information-processing capabilities, human and computer. Yet all communication between the two must pass the low-resolution, narrow-band video display terminal, which chokes off fast, precise, and complex communication. (p.89, Envisioning Information, 1990, Edward Tufte)

Clearly, screen resolutions have progressed very significantly since 1990 such that HD displays (e.g. Retina) are providing resolution and colour/contrast ranges much closer to the range of the human eye to perceive. To this we are now adding virtual reality, data walls and data rooms. All of these are permutations of "bigger display spaces" to display more data. Its cool and sexy and great for University PR but does it work? (Doubtless this risks being very unpopular with certain groups at UTS) Does the human mind have the capacity to work in the round, holding context from one part of the room to the next? We have trouble maintaining data context flipping a page so I'll let you decide how easily we maintain that context turning around. So what does that mean for the super-sexy, very expensive displays - use them wisely. They are not without merit or purpose but just throwing stuff up there to show off risks falling into a world that Tufte might describe as "mega chart junk land".

```{r echo=FALSE, fig.cap="Mine's Bigger...", out.width="60%"}
knitr::include_graphics("Images/minesbigger.jpg", dpi = NA)
```
There is an important philosophical point to be made here. If you really need a 360° view of your data to explain it - do you actually understand it that well? It goes back to the underlying requirement that the author understand the message before trying to convey it.

With that said, these new display technologies are understandably being played with, people are learning what can be done and how to do it - hopefully as part of that they will also learn if/when they actually need 360° views (VR, data rooms). Don't let the medium get bigger than the message.

#### Intelligent Analytics - the Good, the Bad and the Less Ugly

Looking at the array of smart business intelligence tools being brought to market (e.g. Tableau, Sisense, Periscope) it is clear that the integration of data access with data analytics is progressing at pace with a big component of these visualisation tools being their libraries of data access layers and data wrangling tools. This work is directed at removing the peripheral effort from the work involved with analysing and presenting information about data. Visualisation tools are being built/interfaced into stream processing solutions/environments like AWS Kinesis to provide real time data visualisations more simply. Open source tools like Kibana and Elasticsearch are providing accessible functionality while R and Python extensions like Shiny apps, ipywidgets and Bokeh plots are providing similar (if less readily accessible) functionality in the machine learning community space.

The power of the commercial tools to provide tips, advice and suggestions is one of their big commercial selling points and if they are being used for data investigation then this is not a bad thing. It doubtless streamlines the process of investigating and understanding data. If used for this purpose this sort of guided analytics is useful but care needs to be taken that the guidance doesn't limit the analyst's ability/willingness to do the hard work to understand all the possible interpretations of the data they are viewing. Worse still, the easier it is to produce good looking visualisations, the greater the temptation/capacity to present data that is not truly understood by the "author" of the visualisation.

```{r echo=FALSE, fig.cap="Simple Really"}
knitr::include_graphics("Images/justpushthis.png", dpi = NA)
```
A scan of the various (newer) data visualisation tools shows an increasing awareness of how to present data (the less ugly). Being a commercial marketplace there remains (at least in the demo side) a preponderance of the gaudy, flashy visualisations but that is to be expected. The move to the pastel palettes, fainter lines, less cluttered, confronting visuals are all improvements on the clunky, flashy graphics of the 90's and 2000's but the balance between understanding the data (the message) and the best way to present it so as to be easily consumed by its observer (the medium) remains a challenge. This is not least because there are a lot of skills required for both those tasks.

Thus, data analytics is moving forward in:

- improving access to source data
- improving exposure of data/information (interactive visualisations, live visualisations)
- tentative steps to use new display technologies
- better physical (perceptual) properties of visualisations

#### Recommendations

So what are the best (or least worse) tools options available today? There really is no single recommendation that can be made but the questions to be considered might guide any selection process:

- What is your objective?
- Where is your data?
- How much access and wrangling is required?
- Is your data real-time?
- What are your circumstances (corporate budget, personal or research)?
- What are you priorities (analysis, presentation)?
- What are your legacy technical and political constraints?

A wily consultant would read this as an opportunity in and of itself.

The tools are less the issue than the desired outcome. Visualisations make data more accessible - large volumes of data can be represented in a small amount of space, data can be presented in an approachable manner to colleagues, customers and the public. The adoption of data visualisation as an integral part of how information is presented rather than as a fad or gimmick is progressing apace so if you read some of Tufte's work or that of predecessors and more recent data visualisation advocates and bear the advice in mind when building data visualisations then that is the best start that can be made.

### The Future of Visualisations

So, more data, from more sources is being amalgamated more effectively. Businesses and researchers are looking for ways to better transfer understanding of the information buried in those large, complex data sets. What might happen next?

The gimmicky/fad nature of some of the display formats (VR, data wall, etc.) will diminish with the combination of a better understanding of their applied values and improvements in tools that utilise the capacities of these technologies. This probably isn't the next big step in data visualisations, however. 
The big steps happen when components that already exist are integrated more effectively. There is a slow move away from traditional reports-based business operations to dashboards and real-time awareness of the state of a business, market, campaign, etc. The nirvana of business intelligence is to amalgamate all the disparate data sources available to a business in a manner that exposes the underlying forces/reasons behind business trends. The data access tools are facilitating the move towards this nirvana. Once the data is exposed then the next two steps will be:

1. Use data visualisations as real-time views (or historical real-time views) of the state of a business (move away from tables and reports).
2. Provide visualisation interfaces (now we get to Minority Report territory) linked to business models allowing business planners to see the impacts of different business decisions and strategies.

As to the next area of advanced visualisation research, perhaps image processing neural networks can be used as a starting point to reverse engineer the principal visual vectors of understanding.

### Bibliography

Imhof and collaborator 1969, *Schulkarte des Kantons Zürich 1:150 000* Orell Füssli AG, Zürich. 

Tufte, Edward 2001, *The Visual Display of Quantitactie Information*, Graphics Press

Tufte, Edward 1990, *Envisioning Information*, Graphics Press


## Corinna: ON SELF-SERVE ANALYTICS AND DATA DEMOCRATISATION

The ability to enable evidence based and data driven decision making in the workplace has been evolving in the data science industry through the introduction of self-service data analytics tools. Speculators such as Gartner predict that by 2020, self-service business intelligence applications will make up 80% of all enterprise reporting (Dykes 2016). Self-service analytics seeks to provide novice analysts and non-technical business users with the capability to access and use or manipulate data with the hope that these activities will lead to new knowledge (Rouse 2014). Vendors including Tableau, Power BI and Hyper Anna, amongst others are investing into this trend by combining artificial intelligence solutions or user interfaces to manage the thirst of non-technical users for data. Opening up analytics to wider audiences promises to develop new insights, knowledge and innovation by crowdsourcing minds (Kitchin 2014). Therefore, self-service analytical tools are enablers to the effects of data democratisation, breaking down data silos, and providing access to data when and where it is needed at any given moment (Kitchin 2014).

The push for evidence-based thinking in the workplace is justified by a legacy of successful outcomes of this approach in many industries especially medicine. The medical field provides a golden standard of an area where evidence based decision making is clearly valuable. Historically, medicine has relied on funded random controlled trials and other forms of formal research to develop standards for decision making; favouring treatments which had been proven to be most effective in practice (Lumen 2017). By relying on data driven evidence, much of the uncertainty about treatment practices has been removed, further improving the quality of services. Primarily evidence based practices aim to improve the quality of decision making by justifying actions and applying knowledge derived from data. The flow of knowledge development can be represented by the knowledge pyramid below, where data are first abstracted from the world before being processed and repackaged into usable artefacts (Kitchin 2014).

```{r echo=FALSE, fig.cap="A Knowledge Pyramid (taken from Kitchin 2014 and adapted from Adler 1986 and McCandless 2010)"}
knitr::include_graphics("Images/corinna_36111/corinna_36111_a1_knowledge_pyramid.png", dpi = NA)
```

Traditionally, due to the costs and constraints of generating data, the practices of generating new knowledge with data has been constrained to larger entities that could afford the funding and personnel required (Kitchin 2014, Bowker 2000). Smaller amounts of data were formally collected in studies designed with established methodologies and modes of analysis, as well as rules of conduct (Kitchin 2014, Bowker 2000). There is a long reaching record of producing answers to tailored and specific research questions and iteration on the scientific process. As phenomena become easier to monitor with the help of the digitisation of data, the amount of data, technologies and techniques available become more accessible at a lower cost to time and effort (Brynjolfsson & McAfee 2014). Concerns have arisen over the risks of misinterpretation, and misuse of information generated in the data by untrained users (Marr 2017, Dykes 2016 and Harris 2012).

#### ON BIAS

Untrained users may be unaware of and unable to assert control over personal biases. There have been multiple varieties of bias identified through the iterations of scientific practice including observer bias and other experimental effects that occur when researchers' expectations influence study and data outcomes (Holman et.al. 2015 & Young 2009). Biases may be influenced by the following:

-	Researchers expect or assume specific occurrences
-	Research design encourages human subject or researchers to preferentially detect or focus on and recall outcomes that affirm beliefs
-	Analysis or data recording that requires subjective judgements
-	Incentives and agendas or conflicts of interest

The effects of bias pervade multiple stages of formal studies and primary data, and so this bias can also affect informal studies, secondary and tertiary data of all sizes (Young 2009). Some of the traditional approaches to control bias and improve credibility include the use of blinding, randomised sampling and peer review. Peer review can be considered the bedrock of credibility for formal studies (Wheeler 2011). Since peer review relies on willing participation between academics to critically assess studies, there are limitations to its power. Hence, peer reviews can also be subject to some biases and conflicts of interest. 

Many organisations recognize that data in the hands of a few data experts can be powerful, and are hopeful that data at the fingertips of many more domain experts and other staff members will be truly revolutionary, improving knowledge output, efficiency, flexibility or quality of work (Kitchin 2014) The management and interpretation of data through a community of users has the potential to crowdsource insights in a new dynamic that can be likened to peer review. For this reason, the power of self-serve analytics when competently governed and supported may prove more efficient and enriching for the development of industry knowledge than previous infrastructures have allowed.

Self-service data analytics models provide a new means to conduct collaboration and peer review. Especially if the functionality to collaborate on understanding data is integrated into the user interface, the review of insights may occur as they are developed. With the current dashboard solutions and reporting mechanisms, the contesting of information is more formalised and structured. A collaborative environment produced by a well implemented self-service analytics strategy has the potential to create collaborative support from peers and mentors that both empowers users and facilitates user learning experiences, improving ways of justifying decisions and developing unique results in a domain (Chesler et. al 2013).

#### META DATA AND DATA CONTEXTS

The data does not speak for itself and people are a large component to the production of data driven knowledge. The perception that data is objective has pervaded into industry due to much of the scientific work conducted with "small data" (Kitchin 2011, Michener 2009). However, imperfections in "small data" research have been historically identified as "artifacts", errors in results or manmade imperfections that distort the properties of the subjects (Schmidt & Hunter 2015). 

"Data do not exist independently of ideas, techniques, systems, people and contexts, regardless of them often being presented in this manner." (Kitchin 2014)

Although data may have been data widely thought of as benign "raw" elements, which have been abstracted from the world neutrally and objectively, there are many claims to suggest otherwise (Kitchin 2014, Michener 2009). Data are described from established normative, political and ethical processes where decisions about generalisations, assumptions and representations as well as what remains visible and invisible have consequences on the subsequent analysis and conclusions (Kitchin 2014). 

If data is so socially constructed and ideologically loaded from its conception, then ignoring these contextual aspects about the data risk misinterpretation and misjudgement. Not only this but the storage and sharing of the data becomes problematic if these artefacts from the data are not also passed on (Zimmermann 2008 & Bowker 2000). Unfortunately, the tidy formats that data are transferred in and stored (such as within databases) may fail to maintain the important metadata and information regarding the original agendas of the data (Kitchin 2014). Furthermore, much of repurposed information may not have been maintained to a standard that ensures data artefacts are shared (Zimmermann 2008, Michener 2009). The data can thus become uncoupled from its original political and social contexts leaving only what the organisational rules, philosophies and practices determine to be important (Kitchin 2014).

The use of data formats and advances in database and storage options continue to allow for more and more unstructured and unprocessed forms of data to be stored (Song & Zhu 2016, Kitchin 2014, & Service 2017). For instance, unlike traditional data repositories, a data lake is a store of unformatted data where pathways and processes are required to explore the data, since most organisations contain multiple applications with variable non-combined formats (McKennar 2016). Yet throwing all data formats into a 'data-lake' may not be the best nor gentlest approach to meeting the thirst for data. Whilst the data stored in data lakes may comply with currently accepted data standards, there is often still a lack of documentation and commonality in standardisation, especially when data is retained from research that has previously been informally stored (McKennar 2016, Kitchin 2014). Much of the data used to develop knowledge in the past has been lost in favour of aggregations or when personal move on, where only the most valuable datasets of cultural and political significance have been retained in data archives (Michener 2009). Again, the uncoupling of data from its context can occur when data is not accountably curated and archived. Secondly, tidy data has quality control, productivity and sense-making advantages; all are vital components to efficiently yielding knowledge from data. Similarly, untidy data is far more difficult to manipulate and interpret for new unfamiliar user groups.

The handover of data artefacts therefore does not have a generic solution and will depend on the capabilities and judgement of governance bodies as well as the availability of documentation. In some cases, the quality of data may be compromised such that it becomes stale and unusable due to pore maintenance or the nature of business operations. For instance, through the nature of operations, application data may not enter the data base offered to users for analysis for several months after entering the business pipeline. Such data is not yet digital, whether or not the database can be updated at regular intervals. The data may eventually join the database but the time taken to process it may skew ongoing trends expressed within visualisations. To prevent stale data, fresh and relevant input to these systems require constant maintenance (Marr 2017). Combining large data segments within data can also exhibit Simpson's Paradox where overall patterns do not reflect the true trends of the separated groups (Huber 2011). It is of great importance that such issues are not overlooked to allow for smooth and correct interactions with data.

#### NON-TECHNICAL USER TRAINING

Simply supplying new user groups with access to data and technology will not guarantee success. Just as a person who is illiterate, cannot gain from a rich library of books and written information, so lack of data literacy and experience with interpretation can prevent the use and value extraction from unprepared user groups (Harris 2012, Dykes 2017). Acknowledging gaps in human centred processes and building the confidence and skills to master the self-service systems will ultimately require the bestowal of knowledge and mentorship from those who have a history with the data and with using data tools. Brynjolfssen and McAfee in 'The Second Machine Age' predict that the exponential gains expected from combinatorial innovation are intended outcomes of serving data to a wider audience (Brynjolfsson & McAfee 2016). The catch for self-service analytics lies in the scalability of supplying the needed mentorship and training to an ever-extending user group.

Even if data could be justified as neutral, the use of data in analysis to develop knowledge, insights and innovation can also become twisted by political and ideological agendas (Young 2009). When data is used to produce knowledge, meaning is derived from complex cognitive processes to form the basis of understanding, explaining and actioning insights (Young 2009). This data analysis stage is human-centred and subjective, with each data consumer framing data from personal knowledge, understanding and experience. 

For half a century data analysis has been framed to emphasise the application of judgement rather than simply applying mathematical and statistical tools (Tukey 1962). Tukey's influential paper elaborates that this judgement is constituted by:

-	Subject matter experience
-	Broad experience of analytical tools and techniques applied to various situations
-	As well as judgement of the obtained abstract results.

For today's consumers of data, the business user and analyst alike, the strengths of these components vary greatly. Self-serve analytics and data democratisation shifts the problems of overly technical and potentially irrelevant reporting from more technically experienced and smaller teams to broader groups of people with potential greater perceptions of the data driven business needs but lack of experience utilising data and its insights. Although the potential of discovery and the productivity of data driven knowledge acquisition may have been amplified in the new analytical climate, there is little evidence to suggest that the value can be attained without the proper preparation of new user groups.

#### SUPPORT RESOURCES

Data analysis has traditionally been one of the most demanding applications of interactive computing since it covers a wide range of tasks and outputs from research to business intelligence reporting (Huber 2011). Languages and tools for analysis have aimed to be both interactive but also programmable to ensure evidence derived from data is repeatable but also customisable as data requirements change (Huber 2011). As a result, data analytics practices have been inaccessible to the technically untrained. However, the widespread use of computing, and the introduction of more natural language programming languages have opened the opportunities for people to become familiar with data manipulation techniques for a lower overhead. 

Huber suggests data analysis for novices should be offered in canned form for routine investigations with more flexible methods and customisations available for deeper research (Huber 2011). Dashboards have been the bread and butter approach for providing users with canned visualisations of data for daily use. Where a dashboard's weaknesses lie such as regarding explanations of the visualisations, updates in the form of reports have been used as a supplement. New vendors such as IBM Watson, Hyper Anna and Data Robot are attempting to hybridise the two approaches so that more customised and complicated analysis can be facilitated by a search sequence. Accessing customised analytics via a search sequence, removes the user's requirement to know and understand code, and opens the data up to new audiences. This new approach introduces new concerns regarding the unknown levels and types of user support required to ensure automated complex modelling are accountably used and understood.

Masking complex data processes behind more user-friendly interfaces is a necessary evolution of these self-serve systems. The consequence is again a lower overhead for training and usability. However, for the user groups that have no ability to investigate the artificial mechanisms and data pipelines behind the scenes, there is a gap in their capacity for data discernment. Without catered and mindful support and mediation of users with the interfaces of these technologies, the quality of interactions is undermined.

#### MISSING PRACTICALITIES FOR TRAINING

"Few academics and organizations willingly scrutinize the processes on which we stake so many of our goods and values. Transparency, confidentiality, gatekeeping, resource allocation, institutional reputations for excellence-all inform our vision of ourselves as fairminded, sound, disinterested critics and inhibit self- reflection." (Wheeler 2011)
As data handling is extrapolated to new audiences, previously unfamiliar with the methods of analysis, the requirement for training will increase with each user. Comprehensive and scalable training is therefore currently lacking. At present, general tutorials from third parties are available from vendors, however this is not enough to ensure responsible data management. It cannot be assumed that new audiences will have the necessary time resources, information structures nor motivation to conduct comprehensive self-directed study to understand the data. Since organisations often operate in private and closed data ecosystems, the support for the use of data may need to be facilitated internally (Floridi 2006). 

Providing support to new users on a large scale is most likely to be solved with virtual solutions. Virtual support with structures like a massive open online course (MOOC) or preferably a massively adaptive complex online simulation (MACROSIM) may provide the information and mentorship infrastructures required (Virtual Internships). Such virtual programs have successfully incorporated a collaborative environment based on learning theories, and encouraged motivation and reflection on action (Chesler et. al 2013, Virtual Internships). 

Improvements for user support in this new frontier will demand input from users. This will likely occur both anecdotally and through activity feeds where the analytics tools may even be used to process data from the processor (Floridi 2006). Data analytics of this cyclical kind will ultimately change or mutate the entire practice (Kitchin 2014). With the bridge between truly self-directed use and guided exploration through mentorship still open, it is my opinion that data experts will still play a role as data gatekeepers in the near future. The influence of such gatekeepers is yet to be fully explored (Leahey 2008).

##### References

Bowker, G.C. (2000) Biodiversity Datadiversity, Social Studies of Science, SAGE Publications Ltd; 30(5) 643-683 
Brynjolfsson, E., & McAfee A., (2016) The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, New York W. W. Norton & Company, London
Chesler, N.C., Arastoopour, G., D'Angelo, C.M., Bagley, E.A. and Williamson Shaffer, D. (2013) Design of a Professional Practice Simulator for Educating and Motivating First-Year Engineering Students, Advances in Engineering Education, American Society for Engineering Education, Madison
Dykes, B. (2016) Self-Service Analytics and the Illusion of Self-Sufficiency, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2016/11/15/self-service-analytics-and-the-illusion-of-self-sufficiency/#70349a54219a
Dykes, B. (2017) Why Companies Must Close The Data Literacy Divide, Forbes, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2017/03/09/why-companies-must-close-the-data-literacy-divide/#6c580d8a369d
Harris, J. (2012) Data Is Useless Without the Skills to Analyze It, Harvard Business Review, last viewed 6 Nov 2017, https://hbr.org/2012/09/data-is-useless-without-the-skills
Holman, L., Head, M. L., Lanfear, R., and Jennions, M.D. (2015) Evidence of Experimental Bias in the Life Sciences: Why We Need Blind Data Recording, PLoS Biology 13(7) 
Huber, P. J. (2011) Data analysis: what can be learned from the past 50 years, Wiley series in probability and statistics. Wiley, Hoboken, N.J.
Kitchin, R. (2014) The Data Revolution: big data, open data, data infrastructures & their consequences., Sage Publications Ptld, London
Leahey, E. (2008) Overseeing Research Practice: The Case of Data Editing, Science, Technology & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 620 
Lumen Evidence Based Decision Making, last viewed 6 Nov 2017, https://courses.lumenlearning.com/wm-principlesofmanagement/chapter/evidence-based-decision-making/
Marr, B. (2017) What is data democratisation, a super simple explanation and the key pros and cons, last viewed 6 Nov 2017, https://www.forbes.com/sites/bernardmarr/2017/07/24/what-is-data-democratization-a-super-simple-explanation-and-the-key-pros-and-cons/#79ae1ce06013
Michener, William K., and Brunt, James W., eds. (2009) Ecological Data: Design, Management and Processing, Hoboken, GB: Wiley-Blackwell, p92-100
McKennar, B. (2016) Data democratization in the age of big data: why data lakes won't work, last viewed 6 Nov 2017, http://www.computerweekly.com/blog/Data-Matters/Data-democratization-in-the-age-of-big-data-why-data-lakes-wont-work
Rouse, M. (2014) Self-service analytics, Tech Target, last viewed 6 Nov 2017, http://searchbusinessanalytics.techtarget.com/definition/self-service-analytics
Service, R. (2017) DNA could store all of the world's data in one room, last viewed 10 Nov 2017, http://www.sciencemag.org/news/2017/03/dna-could-store-all-worlds-data-one-room
Schmidt, F. & Hunter, J. (2015) Methods of meta-analysis, Availability bias, source bias, and publication bias in meta-analysis, SAGE Publications Ltd., London, pp. 513-551
Tukey, J. W. (1962), The Future of Data Analysis, The Annals of Mathemati- cal Statistics, vol. 33, pp. 1-67 
Virtual Internships, About, University of Wisconsin-Madison, last viewed 13 Nov 2017, http://virtualinterns.org/about/
Wheeler, B. (2011) The Ontology of the Scholarly Journal and the Place of Peer Review, Journal of Scholarly Publishing, vol. 42, no. 3, pp. 307-322
Young, S. N. (2009) Bias in the research literature and conflict of interest: an issue for publishers, editors, reviewers and authors, and it is not just about the money, Journal of Psychiatry and Neuroscience; vol. 34, no. 6 pp. 412-417 
Zimmerman, A. S. (2008) New Knowledge from Old Data: The Role of Standards in the Sharing and Reuse of Ecological Data, Science, Technology, & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 631-652

##### Bibliography

The following articles were not required for writing this post but were influential and complementary readings, I recommend exploring these should you have the interest.

Dudley, I. (2016) UNCOMMON SENSE: THE DEMOCRATIZATION OF DATA ANALYSIS, Neilsen Insights last viewed 13 Nov 2017, http://www.nielsen.com/au/en/insights/news/2016/uncommon-sense-the-democratization-of-data-analysis.html
Mallows, C. (2006) Tukey's Paper After 40 Years, Technometrics, American Statistical Association and the American Society for Quality, vol. 48, no. 3
Marr, B. (2017) Why Data Democratization Is Such a Game-Changer In Our Big Data World, last viewed 6 Nov 2017, http://data-informed.com/why-data-democratization-is-such-a-game-changer-in-our-big-data-world/
Moats, D. (2015) Review of Rob Kitchin's The Data Revolution, last viewed 6 Nov 2017, https://www.theoryculturesociety.org/review-of-rob-kitchins-the-data-revolution/
Dykes, B. (2015) The Age Of Data Democratization: How To Effectively Share Data Across Your Business, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2015/09/09/the-age-of-data-democratization-how-to-effectively-share-data-across-your-business/#261201ac6c50
Strom, D & Baker, P. (2017) The Best Self-Service Business Intelligence (BI) Tools of 2017, last viewed 6 Nov 2017, http://au.pcmag.com/cloud-services/41015/guide/the-best-self-service-business-intelligence-bi-tools-of-2017
Kitchin, R. (2014) Rob Kitchin talks about big data, open data and the 'data revolution', Sage Publications Inc., last viewed 6 Nov 2017, https://www.youtube.com/watch?v=QpDfLoUHqE4
Shah HM, Chung KC. Archie Cochrane and his vision for evidence-based medicine. Plastic and reconstructive surgery. 2009;124(3):982-988. doi:10.1097/PRS.0b013e3181b03928. last viewed 6 Nov 2017, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2746659/
On decision making cultures see: https://hbr.org/2012/10/big-data-the-management-revolution



### Imagining Data Futures, the storage and preservation of human data and its legacy

Most of the structured data that has been collected throughout history has been lost or destroyed (Kitchin 2014). Many other information artefacts are either on a race against time for preservation or lost. The deterioration of the storage media, isolated events such as career changes, retirement or death and the general loss of information from meta-data, memory loss, or poor documentation can contribute to the deterioration of data (Michener 2006). The rate of data loss is also frequently increased after the completion or termination of a project (Michener 2006). An example of the timeline of degradation has been visualised below (Michener 2006).
 
```{r echo=FALSE, fig.cap="Figure 1: "Example of the Normal degradation in information content associated with data and metadata over time", where "accidents of changes in storage technology may eliminate access to remaining raw data and meta data at any time" (Taken from Michener 2006)"}
knitr::include_graphics("Images/corinna_36111/corinna_36111_a2_information_entropy.PNG", dpi = NA)
```


Generally, the justification for data deletion may have been in part affected by the physical limitations of data storage, or the accidental corruption of data. Advancements in data storage technology promise to impede data deterioration and corruption (Song & Zhu 2009, Service 2017). Thus, the deletion of data will tend to be triggered by choices.

Information in the form of articles or books were kept in preference to original data. Over time, data was perceived as pre-factual and distinct from information (Kitchin 2014). These books and articles, kept as the aggregated products of studies, had added benefits for preserving privacy where underlying data could no longer be examined in detail. There was no need to hold onto the original data once the meaning of its collection and existence had been fulfilled by a scientific paper (Bowker 2000). Reader's previously were required to accept on faith that statements made within a scientific paper where proven or disproven correctly by scientific methods (Leahey 2008). Increasingly however, the information stored in databases is seen to be the destination, rather than a means to another end (Bowker 2000). People are gaining better access and ability to view and manipulate data and no longer need to rely solely on publications to obtain information (Dykes 2017, Bowker 2000). In fact, the questions for researchers are sometimes hindered by the format of information in the form of "shelves of reports and proceedings" such as in order to better understand the changes long periods of time (Bowker 2000). In the case of monitoring the ozone layer and other environmental phenomena, using data provides more efficient access to information (Bowker 2000).

The barriers to accumulating data have been overcome as the use of digital devices becomes more widespread (Floridi 2006). There have been explosive increases in the production and availability of data which influences the demand for higher density data storage solutions (Song & Zhu 2009). Achievements to date in the development of new data storage technologies illustrate that the physical limitations of current storage solutions will be soon overcome. For example, DNA has been used to prototype a high-density data storage method with the capacity to store 215 petabytes (215 million gigabytes) per gram (Service 2017). DNA can encode digitised files by combining the four nucleotides in a unique sequence; where 1.6-bits of a theoretically possible 1.8-bits of data per nucleotide were successfully used in a recent attempt (Service 2017). The use of DNA for data storage opens the possibility to store accurately all of the world's digitised data for hundreds of thousands of years if kept in a cool dry place (Service 2017). With these kinds of storage conditions available, data can be saved for generations.
Scientific data can be of tremendous future value. Data can be used and re-used to inform a variety of communities from scientists, to students, to policy makers and applied for purposes that improve quality of life (Wallis & Borgman 2011). Data are often expensive to produce or impossible to reproduce, so much so that the deleted datasets may have no replacement (Wallis & Borgman 2011). Denying future generations of this commodity comes at a cost to progress. 

Removing some data and not others introduces the risk that certain population samples or data types will be emphasised over others (Bates 2016). This is especially troubling if the remaining data intentionally or unintentionally represents only majority groups. For many research studies, data is taken about a specific population rather than for them (Thorp 2013). In general research errors and bias are not only related to individual titles, rather are still present in forms such as publication bias, availability bias, and source bias (Scmidt & Hunter 2015). Publication bias is often suspected in meta-analysis, since published studies will tend to show results that are statistically significant and have larger effect sizes than unpublished studies (Scmidt & Hunter 2015). Thus, it is also in the interests of the research community to retain as much quality information to balance these effects.

The value of data as part of a data commons could extend beyond the lifespan of any individual. However, the assertion of the findings derived from old data onto new contexts needs to be done with care. Data corruption is not only confined to physical deterioration. Data, can be conceptualised to have both material as well as social properties (Kitchin 2014). For example, although data based studies conducted on the advantages of circumcision for the prevention of HIV in sub-Saharan Africa have provided adequate evidence for endorsement by the World Health Organisation, generalising these studies to other geographical areas has been contested on the grounds that there was no evidence for a casual mechanism in such studies, along with contextual differences in disease transmission in other parts of the world (Norton 2017). Data and research studies alike are imperfect, where bias, mistakes and social, political, or other contextual baggage exist (Michener 2006).
Even whilst standards of collecting or recording data can assist with quality control and subsequent transferability of data, the reuse and detachment from the data collection process also detaches analysts from important contextual knowledge in many fields of study (Kitchin 2014, Bowler 2000, Zimmermann 2008). A study of the reuse of data by ecologists show that the local context is critical to ecologists' reuse of data (Zimmermann 2008). The knowledge that ecologists acquire through fieldwork for example allows them to recover details about the specific local environment, perhaps too specific to record, to comprehend that data. It is simply not the same when others collect data (Zimmerman 2008).
Then it is troubling that the merging of disparate data, into larger composites, is relatively simple despite the complexity of layered disparate social values and meanings (Bowker 2000). Without proper documentation as well as maintenance of original data, this process may become irreversible, and social and ideological data contexts lost (Bowker 2000). Thus, there is a need to salvage meta-data and documentation for current and future data resources. Salvaging data documentation and contexts is akin to the restoration efforts applied to many artefacts over the years and part of assuring a quality historic legacy for the next generation.
It is not necessarily legitimate to treat the thoughts or activates of someone long since dead as a relevant contribution to present investigations, especially in abstraction from historical contexts (Craig 2002). In the case of some historical documentation, such as for philosophers like Plato, the authors express ideas intended to transcend time and place (Craig 2002) but in contrast, posts on social media, are often intended to have only momentary relevance (Ursic 2016). The reasons and manner for which data is re-used in the future are unknown. George Washington was likely unaware that his dentures would be out on display for all to see at the Mount Vernon Museum in Virginia, over 200 years after his death. The specific meanings and intentions attached to historic data should be observed for what may be missing (Craig 2002, Ursic 2016, Kitchin 2014). 

Just as historical information can and has been used to contribute to current knowledge, awareness of the atmosphere in which data was produced can add important meaning (Craig 2002). 

"Meta-data are the information necessary to understand and effectively use data, including documentation of the data set contents, context, quality, structure and accessibility"(Michener 2006 p). 

The only hope for long term and scalable use of data, no matter the size is to place importance on creating well-documented and securely archived data. 

As data is deposited into repositories, for reuse and potentially long-term storage, those responsible for the data may be no longer be the originators and authors of that data (Wallis & Borgman 2011). If we extend these points about context into the future, imagine when enough time has passed to radically change the way that language is used. In such a situation, any use of language contained in a data set may potentially become misinterpreted or illegible to this new audience. 
When the original data creators are long gone, no persons responsible for the data will be available to revise the data. Then regarding those responsible for data, to what extent are they accountable for documenting meta data and data contexts for either newly generated data or re-used data? 

Personal items and information once only available to those in physical proximity to the deceased, are now also accompanied by traces of a person's activities across the internet. For many organisations, data are collected and deposited into closed ecosystems. Technology companies like Google, Facebook and Apple profit from reselling and sharing data produced by millions of users on their platforms (Ursic 2016). These companies play a role in both data authorship and ownership along with the users. The storing of data does not necessarily change the data ownership, if the human subject is considered a co-author or data owner. Yet, if those managing the data are in control of access and engagement with it (Clark et. al. 2011). Within management of this data and efforts to anonymise and de-identify, the human subjects have more or less relinquished ownership (Clark et. al. 2015). Then, who has the authority to release the data and when are data to be released, if ever? Furthermore, do we each have a right to retrieve our personal public data or is that data considered part of the public domain and digital commons, as a legal "fact" and historical document? Should these data resources remain appart from the common domain, there is also the possibility that a distinction may be made between the "information-rich" and the "information-poor" (Floridi 2006).

Sometimes the destruction of data has been intentional for the purposes of protecting the privacy of study participants. Data may also be deleted by individuals when the data can no longer be relied upon as accurate or complete (Ursic 2016). Data repositories rely on the deposit of materials from the communities they serve, forming a chain of stakeholders from the data creator to the repository and data user (Wallis & Borgman 2011). With respect to human data ethics and sensitive data, the justification of deletion may be spurred by the responsibilities of the researchers to respect the wishes and privacy of the subjects of study after the purposes of the data have been fulfilled (Clark et. al. 2015). This justification implies consent, however when data is instead harvested passively from the public domain or where the subject's identity is not available or easily obtainable, it is possible for data to exist without the human subject's knowledge (Clark et. al. 2015). The new ways that data is retrieved further confound the positions of duty to privacy and ownership of data.

Whilst concerned with increasing the physical longevity of data storage media, we must also turn to the quality of data and the ways that data contexts, publications and documentation are stored. No assumptions should be made that data without such documentation will be self-explanatory or easily understood by new audiences. No matter how advanced and long-term computer memory becomes, human memory is still limited. Whether the data should remain or whether the data cannot continue its legacy into future generations are notoriously hard decisions to make. 
Before data can be preserved for reuse in the future, data quality control must be employed and efforts made to ensure the metadata and documentation are also preserved. The original purpose and origins of data aid the responsible reuse of data, otherwise there are ethical and practical implications for future studies. It is likely that the data that is preserved today will exist long after we perish and in this way, we have the advantage of shaping our history, how we are represented and how we add value to new generations. Yet, what will constitute valuable data cannot be known. Instead, if we are to accept that the data stored today is irreplaceable information, we must also accept that its donation has high value. Framing data sets responsibly and ensuring respect and justice for human subjects are important steps to preserving a responsible data legacy.

##### References
Bates, J. (2016) Towards a critical data science - the complicated relationship between data and the democratic project, last viewed 10 Nov 2016, http://blogs.lse.ac.uk/impactofsocialsciences/2016/01/12/towards-a-critical-data-science-data-and-the-democratic-project/
Bowker, G.C. (2000) Biodiversity Datadiversity, Social Studies of Science, SAGE Publications Ltd; 30(5) 643-683 
Clark, K., Duckham, M., Guillemin, M., Hunter, A., McVernon, J., O'Keefe, C., Pitkin, C., Prawer, S., Sinnott, R., Warr, D., and Waycott, J. (2015) Guidelines for the Ethical Use of Digital Data in Human Research: Part B, last viewed 11 Nov 2017, https://www.carltonconnect.com.au/wp-content/uploads/2015/06/Ethical-Use-of-Digital-Data.pdf
Craig, E., (2002) Philosophy: A Very Short Introduction, Oxford University Press, pp. 684-822 & pp. 822-1051
Dykes, B. (2017) Why Companies Must Close The Data Literacy Divide, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2017/03/09/why-companies-must-close-the-data-literacy-divide/#6c580d8a369d
Floridi, L. (2006), Peering into the Future of the Infosphere, last viewed 10 Nov 2016, http://tidbits.com/article/8686
Kitchin, R. (2014) The Data Revolution: big data, open data, data infrastructures & their consequences., Sage Publications Inc., London
Leahey, E. (2008) Overseeing Research Practice: The Case of Data Editing, Science, Technology & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 620 
Michener, William K., and Brunt, James W., eds. (2009) Ecological Data: Design, Management and Processing, Hoboken, GB: Wiley-Blackwell, p92-100
Norton, A.T. (2017) Foreskin and the molecular politics of risk, Social Studies of Science, SAGE Publications Inc., vol. 47, no. 5, pp. 655-680 
Redman, T.C. (2013), Chapter 1: Data Quality Management Past, Present, and Future: Towards a Management System for Data, Handbook of data quality: research and practice. Springer, New York.
Schmidt, F. & Hunter, J. (2015) Methods of meta-analysis, Availability bias, source bias, and publication bias in meta-analysis, SAGE Publications Ltd., London, pp. 513-551
Service, R. (2017) DNA could store all of the world's data in one room, last viewed 10 Nov 2017, http://www.sciencemag.org/news/2017/03/dna-could-store-all-worlds-data-one-room
Song, Y., Zhu, D. (2009) Preface, High Density Data Storage - Principle, Technology, and Materials, World Scientific. Online version last viewed 10 Nov 2017, http://app.knovel.com/hotlink/toc/id:kpHDDSPTM3/high-density-data-
Thorp, J. (2016) Turning Data Around, last viewed 10 Nov 2017, https://medium.com/memo-random/turning-data-around-7acea1f7479c
Wallis, J. C. & Borgman, C. L. (2011). Who is responsible for data? An exploratory study of data authorship, ownership, and responsibility. Proceedings of the American Society for Information Science and Technology, vol. 48, no. 1, pp. 1-10.
Zimmerman, A. S. (2008) New Knowledge from Old Data: The Role of Standards in the Sharing and Reuse of Ecological Data, Science, Technology, & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 631-652

### ON SELF-SERVE ANALYTICS AND DATA DEMOCRATISATION

The ability to enable evidence based and data driven decision making in the workplace has been evolving in the data science industry through the introduction of self-service data analytics tools. Speculators such as Gartner predict that by 2020, self-service business intelligence applications will make up 80% of all enterprise reporting (Dykes 2016). Self-service analytics seeks to provide novice analysts and non-technical business users with the capability to access and use or manipulate data with the hope that these activities will lead to new knowledge (Rouse 2014). Vendors including Tableau, Power BI and Hyper Anna, amongst others are investing into this trend by combining artificial intelligence solutions or user interfaces to manage the thirst of non-technical users for data. Opening up analytics to wider audiences promises to develop new insights, knowledge and innovation by crowdsourcing minds (Kitchin 2014). Therefore, self-service analytical tools are enablers to the effects of data democratisation, breaking down data silos, and providing access to data when and where it is needed at any given moment (Kitchin 2014).

The push for evidence-based thinking in the workplace is justified by a legacy of successful outcomes of this approach in many industries especially medicine. The medical field provides a golden standard of an area where evidence based decision making is clearly valuable. Historically, medicine has relied on funded random controlled trials and other forms of formal research to develop standards for decision making; favouring treatments which had been proven to be most effective in practice (Lumen 2017). By relying on data driven evidence, much of the uncertainty about treatment practices has been removed, further improving the quality of services. Primarily evidence based practices aim to improve the quality of decision making by justifying actions and applying knowledge derived from data. The flow of knowledge development can be represented by the knowledge pyramid below, where data are first abstracted from the world before being processed and repackaged into usable artefacts (Kitchin 2014).

```{r echo=FALSE, fig.cap="A Knowledge Pyramid (taken from Kitchin 2014 and adapted from Adler 1986 and McCandless 2010)"}
knitr::include_graphics("Images/corinna_36111_a1_knowledge_pyramid.png", dpi = NA)
```

Traditionally, due to the costs and constraints of generating data, the practices of generating new knowledge with data has been constrained to larger entities that could afford the funding and personnel required (Kitchin 2014, Bowker 2000). Smaller amounts of data were formally collected in studies designed with established methodologies and modes of analysis, as well as rules of conduct (Kitchin 2014, Bowker 2000). There is a long reaching record of producing answers to tailored and specific research questions and iteration on the scientific process. As phenomena become easier to monitor with the help of the digitisation of data, the amount of data, technologies and techniques available become more accessible at a lower cost to time and effort (Brynjolfsson & McAfee 2014). Concerns have arisen over the risks of misinterpretation, and misuse of information generated in the data by untrained users (Marr 2017, Dykes 2016 and Harris 2012).

#### ON BIAS

Untrained users may be unaware of and unable to assert control over personal biases. There have been multiple varieties of bias identified through the iterations of scientific practice including observer bias and other experimental effects that occur when researchers' expectations influence study and data outcomes (Holman et.al. 2015 & Young 2009). Biases may be influenced by the following:

-	Researchers expect or assume specific occurrences
-	Research design encourages human subject or researchers to preferentially detect or focus on and recall outcomes that affirm beliefs
-	Analysis or data recording that requires subjective judgements
-	Incentives and agendas or conflicts of interest

The effects of bias pervade multiple stages of formal studies and primary data, and so this bias can also affect informal studies, secondary and tertiary data of all sizes (Young 2009). Some of the traditional approaches to control bias and improve credibility include the use of blinding, randomised sampling and peer review. Peer review can be considered the bedrock of credibility for formal studies (Wheeler 2011). Since peer review relies on willing participation between academics to critically assess studies, there are limitations to its power. Hence, peer reviews can also be subject to some biases and conflicts of interest. 

Many organisations recognize that data in the hands of a few data experts can be powerful, and are hopeful that data at the fingertips of many more domain experts and other staff members will be truly revolutionary, improving knowledge output, efficiency, flexibility or quality of work (Kitchin 2014) The management and interpretation of data through a community of users has the potential to crowdsource insights in a new dynamic that can be likened to peer review. For this reason, the power of self-serve analytics when competently governed and supported may prove more efficient and enriching for the development of industry knowledge than previous infrastructures have allowed.

Self-service data analytics models provide a new means to conduct collaboration and peer review. Especially if the functionality to collaborate on understanding data is integrated into the user interface, the review of insights may occur as they are developed. With the current dashboard solutions and reporting mechanisms, the contesting of information is more formalised and structured. A collaborative environment produced by a well implemented self-service analytics strategy has the potential to create collaborative support from peers and mentors that both empowers users and facilitates user learning experiences, improving ways of justifying decisions and developing unique results in a domain (Chesler et. al 2013).

#### META DATA AND DATA CONTEXTS

The data does not speak for itself and people are a large component to the production of data driven knowledge. The perception that data is objective has pervaded into industry due to much of the scientific work conducted with "small data" (Kitchin 2011, Michener 2009). However, imperfections in "small data" research have been historically identified as "artifacts", errors in results or manmade imperfections that distort the properties of the subjects (Schmidt & Hunter 2015). 

"Data do not exist independently of ideas, techniques, systems, people and contexts, regardless of them often being presented in this manner." (Kitchin 2014)

Although data may have been data widely thought of as benign "raw" elements, which have been abstracted from the world neutrally and objectively, there are many claims to suggest otherwise (Kitchin 2014, Michener 2009). Data are described from established normative, political and ethical processes where decisions about generalisations, assumptions and representations as well as what remains visible and invisible have consequences on the subsequent analysis and conclusions (Kitchin 2014). 

If data is so socially constructed and ideologically loaded from its conception, then ignoring these contextual aspects about the data risk misinterpretation and misjudgement. Not only this but the storage and sharing of the data becomes problematic if these artefacts from the data are not also passed on (Zimmermann 2008 & Bowker 2000). Unfortunately, the tidy formats that data are transferred in and stored (such as within databases) may fail to maintain the important metadata and information regarding the original agendas of the data (Kitchin 2014). Furthermore, much of repurposed information may not have been maintained to a standard that ensures data artefacts are shared (Zimmermann 2008, Michener 2009). The data can thus become uncoupled from its original political and social contexts leaving only what the organisational rules, philosophies and practices determine to be important (Kitchin 2014).

The use of data formats and advances in database and storage options continue to allow for more and more unstructured and unprocessed forms of data to be stored (Song & Zhu 2016, Kitchin 2014, & Service 2017). For instance, unlike traditional data repositories, a data lake is a store of unformatted data where pathways and processes are required to explore the data, since most organisations contain multiple applications with variable non-combined formats (McKennar 2016). Yet throwing all data formats into a 'data-lake' may not be the best nor gentlest approach to meeting the thirst for data. Whilst the data stored in data lakes may comply with currently accepted data standards, there is often still a lack of documentation and commonality in standardisation, especially when data is retained from research that has previously been informally stored (McKennar 2016, Kitchin 2014). Much of the data used to develop knowledge in the past has been lost in favour of aggregations or when personal move on, where only the most valuable datasets of cultural and political significance have been retained in data archives (Michener 2009). Again, the uncoupling of data from its context can occur when data is not accountably curated and archived. Secondly, tidy data has quality control, productivity and sense-making advantages; all are vital components to efficiently yielding knowledge from data. Similarly, untidy data is far more difficult to manipulate and interpret for new unfamiliar user groups.

The handover of data artefacts therefore does not have a generic solution and will depend on the capabilities and judgement of governance bodies as well as the availability of documentation. In some cases, the quality of data may be compromised such that it becomes stale and unusable due to pore maintenance or the nature of business operations. For instance, through the nature of operations, application data may not enter the data base offered to users for analysis for several months after entering the business pipeline. Such data is not yet digital, whether or not the database can be updated at regular intervals. The data may eventually join the database but the time taken to process it may skew ongoing trends expressed within visualisations. To prevent stale data, fresh and relevant input to these systems require constant maintenance (Marr 2017). Combining large data segments within data can also exhibit Simpson's Paradox where overall patterns do not reflect the true trends of the separated groups (Huber 2011). It is of great importance that such issues are not overlooked to allow for smooth and correct interactions with data.

#### NON-TECHNICAL USER TRAINING

Simply supplying new user groups with access to data and technology will not guarantee success. Just as a person who is illiterate, cannot gain from a rich library of books and written information, so lack of data literacy and experience with interpretation can prevent the use and value extraction from unprepared user groups (Harris 2012, Dykes 2017). Acknowledging gaps in human centred processes and building the confidence and skills to master the self-service systems will ultimately require the bestowal of knowledge and mentorship from those who have a history with the data and with using data tools. Brynjolfssen and McAfee in 'The Second Machine Age' predict that the exponential gains expected from combinatorial innovation are intended outcomes of serving data to a wider audience (Brynjolfsson & McAfee 2016). The catch for self-service analytics lies in the scalability of supplying the needed mentorship and training to an ever-extending user group.

Even if data could be justified as neutral, the use of data in analysis to develop knowledge, insights and innovation can also become twisted by political and ideological agendas (Young 2009). When data is used to produce knowledge, meaning is derived from complex cognitive processes to form the basis of understanding, explaining and actioning insights (Young 2009). This data analysis stage is human-centred and subjective, with each data consumer framing data from personal knowledge, understanding and experience. 

For half a century data analysis has been framed to emphasise the application of judgement rather than simply applying mathematical and statistical tools (Tukey 1962). Tukey's influential paper elaborates that this judgement is constituted by:

-	Subject matter experience
-	Broad experience of analytical tools and techniques applied to various situations
-	As well as judgement of the obtained abstract results.

For today's consumers of data, the business user and analyst alike, the strengths of these components vary greatly. Self-serve analytics and data democratisation shifts the problems of overly technical and potentially irrelevant reporting from more technically experienced and smaller teams to broader groups of people with potential greater perceptions of the data driven business needs but lack of experience utilising data and its insights. Although the potential of discovery and the productivity of data driven knowledge acquisition may have been amplified in the new analytical climate, there is little evidence to suggest that the value can be attained without the proper preparation of new user groups.

#### SUPPORT RESOURCES

Data analysis has traditionally been one of the most demanding applications of interactive computing since it covers a wide range of tasks and outputs from research to business intelligence reporting (Huber 2011). Languages and tools for analysis have aimed to be both interactive but also programmable to ensure evidence derived from data is repeatable but also customisable as data requirements change (Huber 2011). As a result, data analytics practices have been inaccessible to the technically untrained. However, the widespread use of computing, and the introduction of more natural language programming languages have opened the opportunities for people to become familiar with data manipulation techniques for a lower overhead. 

Huber suggests data analysis for novices should be offered in canned form for routine investigations with more flexible methods and customisations available for deeper research (Huber 2011). Dashboards have been the bread and butter approach for providing users with canned visualisations of data for daily use. Where a dashboard's weaknesses lie such as regarding explanations of the visualisations, updates in the form of reports have been used as a supplement. New vendors such as IBM Watson, Hyper Anna and Data Robot are attempting to hybridise the two approaches so that more customised and complicated analysis can be facilitated by a search sequence. Accessing customised analytics via a search sequence, removes the user's requirement to know and understand code, and opens the data up to new audiences. This new approach introduces new concerns regarding the unknown levels and types of user support required to ensure automated complex modelling are accountably used and understood.

Masking complex data processes behind more user-friendly interfaces is a necessary evolution of these self-serve systems. The consequence is again a lower overhead for training and usability. However, for the user groups that have no ability to investigate the artificial mechanisms and data pipelines behind the scenes, there is a gap in their capacity for data discernment. Without catered and mindful support and mediation of users with the interfaces of these technologies, the quality of interactions is undermined.

#### MISSING PRACTICALITIES FOR TRAINING

"Few academics and organizations willingly scrutinize the processes on which we stake so many of our goods and values. Transparency, confidentiality, gatekeeping, resource allocation, institutional reputations for excellence-all inform our vision of ourselves as fairminded, sound, disinterested critics and inhibit self- reflection." (Wheeler 2011)
As data handling is extrapolated to new audiences, previously unfamiliar with the methods of analysis, the requirement for training will increase with each user. Comprehensive and scalable training is therefore currently lacking. At present, general tutorials from third parties are available from vendors, however this is not enough to ensure responsible data management. It cannot be assumed that new audiences will have the necessary time resources, information structures nor motivation to conduct comprehensive self-directed study to understand the data. Since organisations often operate in private and closed data ecosystems, the support for the use of data may need to be facilitated internally (Floridi 2006). 

Providing support to new users on a large scale is most likely to be solved with virtual solutions. Virtual support with structures like a massive open online course (MOOC) or preferably a massively adaptive complex online simulation (MACROSIM) may provide the information and mentorship infrastructures required (Virtual Internships). Such virtual programs have successfully incorporated a collaborative environment based on learning theories, and encouraged motivation and reflection on action (Chesler et. al 2013, Virtual Internships). 

Improvements for user support in this new frontier will demand input from users. This will likely occur both anecdotally and through activity feeds where the analytics tools may even be used to process data from the processor (Floridi 2006). Data analytics of this cyclical kind will ultimately change or mutate the entire practice (Kitchin 2014). With the bridge between truly self-directed use and guided exploration through mentorship still open, it is my opinion that data experts will still play a role as data gatekeepers in the near future. The influence of such gatekeepers is yet to be fully explored (Leahey 2008).

##### References

Bowker, G.C. (2000) Biodiversity Datadiversity, Social Studies of Science, SAGE Publications Ltd; 30(5) 643-683 
Brynjolfsson, E., & McAfee A., (2016) The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, New York W. W. Norton & Company, London
Chesler, N.C., Arastoopour, G., D'Angelo, C.M., Bagley, E.A. and Williamson Shaffer, D. (2013) Design of a Professional Practice Simulator for Educating and Motivating First-Year Engineering Students, Advances in Engineering Education, American Society for Engineering Education, Madison
Dykes, B. (2016) Self-Service Analytics and the Illusion of Self-Sufficiency, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2016/11/15/self-service-analytics-and-the-illusion-of-self-sufficiency/#70349a54219a
Dykes, B. (2017) Why Companies Must Close The Data Literacy Divide, Forbes, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2017/03/09/why-companies-must-close-the-data-literacy-divide/#6c580d8a369d
Harris, J. (2012) Data Is Useless Without the Skills to Analyze It, Harvard Business Review, last viewed 6 Nov 2017, https://hbr.org/2012/09/data-is-useless-without-the-skills
Holman, L., Head, M. L., Lanfear, R., and Jennions, M.D. (2015) Evidence of Experimental Bias in the Life Sciences: Why We Need Blind Data Recording, PLoS Biology 13(7) 
Huber, P. J. (2011) Data analysis: what can be learned from the past 50 years, Wiley series in probability and statistics. Wiley, Hoboken, N.J.
Kitchin, R. (2014) The Data Revolution: big data, open data, data infrastructures & their consequences., Sage Publications Ptld, London
Leahey, E. (2008) Overseeing Research Practice: The Case of Data Editing, Science, Technology & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 620 
Lumen Evidence Based Decision Making, last viewed 6 Nov 2017, https://courses.lumenlearning.com/wm-principlesofmanagement/chapter/evidence-based-decision-making/
Marr, B. (2017) What is data democratisation, a super simple explanation and the key pros and cons, last viewed 6 Nov 2017, https://www.forbes.com/sites/bernardmarr/2017/07/24/what-is-data-democratization-a-super-simple-explanation-and-the-key-pros-and-cons/#79ae1ce06013
Michener, William K., and Brunt, James W., eds. (2009) Ecological Data: Design, Management and Processing, Hoboken, GB: Wiley-Blackwell, p92-100
McKennar, B. (2016) Data democratization in the age of big data: why data lakes won't work, last viewed 6 Nov 2017, http://www.computerweekly.com/blog/Data-Matters/Data-democratization-in-the-age-of-big-data-why-data-lakes-wont-work
Rouse, M. (2014) Self-service analytics, Tech Target, last viewed 6 Nov 2017, http://searchbusinessanalytics.techtarget.com/definition/self-service-analytics
Service, R. (2017) DNA could store all of the world's data in one room, last viewed 10 Nov 2017, http://www.sciencemag.org/news/2017/03/dna-could-store-all-worlds-data-one-room
Schmidt, F. & Hunter, J. (2015) Methods of meta-analysis, Availability bias, source bias, and publication bias in meta-analysis, SAGE Publications Ltd., London, pp. 513-551
Tukey, J. W. (1962), The Future of Data Analysis, The Annals of Mathemati- cal Statistics, vol. 33, pp. 1-67 
Virtual Internships, About, University of Wisconsin-Madison, last viewed 13 Nov 2017, http://virtualinterns.org/about/
Wheeler, B. (2011) The Ontology of the Scholarly Journal and the Place of Peer Review, Journal of Scholarly Publishing, vol. 42, no. 3, pp. 307-322
Young, S. N. (2009) Bias in the research literature and conflict of interest: an issue for publishers, editors, reviewers and authors, and it is not just about the money, Journal of Psychiatry and Neuroscience; vol. 34, no. 6 pp. 412-417 
Zimmerman, A. S. (2008) New Knowledge from Old Data: The Role of Standards in the Sharing and Reuse of Ecological Data, Science, Technology, & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 631-652

##### Bibliography

The following articles were not required for writing this post but were influential and complementary readings, I recommend exploring these should you have the interest.

Dudley, I. (2016) UNCOMMON SENSE: THE DEMOCRATIZATION OF DATA ANALYSIS, Neilsen Insights last viewed 13 Nov 2017, http://www.nielsen.com/au/en/insights/news/2016/uncommon-sense-the-democratization-of-data-analysis.html
Mallows, C. (2006) Tukey's Paper After 40 Years, Technometrics, American Statistical Association and the American Society for Quality, vol. 48, no. 3
Marr, B. (2017) Why Data Democratization Is Such a Game-Changer In Our Big Data World, last viewed 6 Nov 2017, http://data-informed.com/why-data-democratization-is-such-a-game-changer-in-our-big-data-world/
Moats, D. (2015) Review of Rob Kitchin's The Data Revolution, last viewed 6 Nov 2017, https://www.theoryculturesociety.org/review-of-rob-kitchins-the-data-revolution/
Dykes, B. (2015) The Age Of Data Democratization: How To Effectively Share Data Across Your Business, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2015/09/09/the-age-of-data-democratization-how-to-effectively-share-data-across-your-business/#261201ac6c50
Strom, D & Baker, P. (2017) The Best Self-Service Business Intelligence (BI) Tools of 2017, last viewed 6 Nov 2017, http://au.pcmag.com/cloud-services/41015/guide/the-best-self-service-business-intelligence-bi-tools-of-2017
Kitchin, R. (2014) Rob Kitchin talks about big data, open data and the 'data revolution', Sage Publications Inc., last viewed 6 Nov 2017, https://www.youtube.com/watch?v=QpDfLoUHqE4
Shah HM, Chung KC. Archie Cochrane and his vision for evidence-based medicine. Plastic and reconstructive surgery. 2009;124(3):982-988. doi:10.1097/PRS.0b013e3181b03928. last viewed 6 Nov 2017, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2746659/
On decision making cultures see: https://hbr.org/2012/10/big-data-the-management-revolution



## Herry

## Passiona

## Rory

## Tracy
