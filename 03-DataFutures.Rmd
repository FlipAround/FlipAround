# Data Futures

## Andrew

## Corinna 

### On the self-serve data analystics trend and data democratisation

```{r echo=FALSE, fig.cap="A Knowledge Pyramid (taken from Kitchin 2014 and adapted from Adler 1986 and McCandless 2010)"}
knitr::include_graphics("Images/corinna_36111/corinna_36111_a1_knowledge_pyramid.png", dpi = NA)
```


### Imagining Data Futures, the storage and preservation of human data and its legacy

Most of the structured data that has been collected throughout history has been lost or destroyed (Kitchin 2014). Many other information artefacts are either on a race against time for preservation or lost. The deterioration of the storage media, isolated events such as career changes, retirement or death and the general loss of information from meta-data, memory loss, or poor documentation can contribute to the deterioration of data (Michener 2006). The rate of data loss is also frequently increased after the completion or termination of a project (Michener 2006). An example of the timeline of degradation has been visualised below (Michener 2006).
 
```{r echo=FALSE, fig.cap="Figure 1: "Example of the Normal degradation in information content associated with data and metadata over time", where "accidents of changes in storage technology may eliminate access to remaining raw data and meta data at any time" (Taken from Michener 2006)"}
knitr::include_graphics("Images/corinna_36111/corinna_36111_a2_information_entropy.PNG", dpi = NA)
```


Generally, the justification for data deletion may have been in part affected by the physical limitations of data storage, or the accidental corruption of data. Advancements in data storage technology promise to impede data deterioration and corruption (Song & Zhu 2009, Service 2017). Thus, the deletion of data will tend to be triggered by choices.

Information in the form of articles or books were kept in preference to original data. Over time, data was perceived as pre-factual and distinct from information (Kitchin 2014). These books and articles, kept as the aggregated products of studies, had added benefits for preserving privacy where underlying data could no longer be examined in detail. There was no need to hold onto the original data once the meaning of its collection and existence had been fulfilled by a scientific paper (Bowker 2000). Reader's previously were required to accept on faith that statements made within a scientific paper where proven or disproven correctly by scientific methods (Leahey 2008). Increasingly however, the information stored in databases is seen to be the destination, rather than a means to another end (Bowker 2000). People are gaining better access and ability to view and manipulate data and no longer need to rely solely on publications to obtain information (Dykes 2017, Bowker 2000). In fact, the questions for researchers are sometimes hindered by the format of information in the form of "shelves of reports and proceedings" such as in order to better understand the changes long periods of time (Bowker 2000). In the case of monitoring the ozone layer and other environmental phenomena, using data provides more efficient access to information (Bowker 2000).

The barriers to accumulating data have been overcome as the use of digital devices becomes more widespread (Floridi 2006). There have been explosive increases in the production and availability of data which influences the demand for higher density data storage solutions (Song & Zhu 2009). Achievements to date in the development of new data storage technologies illustrate that the physical limitations of current storage solutions will be soon overcome. For example, DNA has been used to prototype a high-density data storage method with the capacity to store 215 petabytes (215 million gigabytes) per gram (Service 2017). DNA can encode digitised files by combining the four nucleotides in a unique sequence; where 1.6-bits of a theoretically possible 1.8-bits of data per nucleotide were successfully used in a recent attempt (Service 2017). The use of DNA for data storage opens the possibility to store accurately all of the world's digitised data for hundreds of thousands of years if kept in a cool dry place (Service 2017). With these kinds of storage conditions available, data can be saved for generations.
Scientific data can be of tremendous future value. Data can be used and re-used to inform a variety of communities from scientists, to students, to policy makers and applied for purposes that improve quality of life (Wallis & Borgman 2011). Data are often expensive to produce or impossible to reproduce, so much so that the deleted datasets may have no replacement (Wallis & Borgman 2011). Denying future generations of this commodity comes at a cost to progress. 

Removing some data and not others introduces the risk that certain population samples or data types will be emphasised over others (Bates 2016). This is especially troubling if the remaining data intentionally or unintentionally represents only majority groups. For many research studies, data is taken about a specific population rather than for them (Thorp 2013). In general research errors and bias are not only related to individual titles, rather are still present in forms such as publication bias, availability bias, and source bias (Scmidt & Hunter 2015). Publication bias is often suspected in meta-analysis, since published studies will tend to show results that are statistically significant and have larger effect sizes than unpublished studies (Scmidt & Hunter 2015). Thus, it is also in the interests of the research community to retain as much quality information to balance these effects.

The value of data as part of a data commons could extend beyond the lifespan of any individual. However, the assertion of the findings derived from old data onto new contexts needs to be done with care. Data corruption is not only confined to physical deterioration. Data, can be conceptualised to have both material as well as social properties (Kitchin 2014). For example, although data based studies conducted on the advantages of circumcision for the prevention of HIV in sub-Saharan Africa have provided adequate evidence for endorsement by the World Health Organisation, generalising these studies to other geographical areas has been contested on the grounds that there was no evidence for a casual mechanism in such studies, along with contextual differences in disease transmission in other parts of the world (Norton 2017). Data and research studies alike are imperfect, where bias, mistakes and social, political, or other contextual baggage exist (Michener 2006).
Even whilst standards of collecting or recording data can assist with quality control and subsequent transferability of data, the reuse and detachment from the data collection process also detaches analysts from important contextual knowledge in many fields of study (Kitchin 2014, Bowler 2000, Zimmermann 2008). A study of the reuse of data by ecologists show that the local context is critical to ecologists' reuse of data (Zimmermann 2008). The knowledge that ecologists acquire through fieldwork for example allows them to recover details about the specific local environment, perhaps too specific to record, to comprehend that data. It is simply not the same when others collect data (Zimmerman 2008).
Then it is troubling that the merging of disparate data, into larger composites, is relatively simple despite the complexity of layered disparate social values and meanings (Bowker 2000). Without proper documentation as well as maintenance of original data, this process may become irreversible, and social and ideological data contexts lost (Bowker 2000). Thus, there is a need to salvage meta-data and documentation for current and future data resources. Salvaging data documentation and contexts is akin to the restoration efforts applied to many artefacts over the years and part of assuring a quality historic legacy for the next generation.
It is not necessarily legitimate to treat the thoughts or activates of someone long since dead as a relevant contribution to present investigations, especially in abstraction from historical contexts (Craig 2002). In the case of some historical documentation, such as for philosophers like Plato, the authors express ideas intended to transcend time and place (Craig 2002) but in contrast, posts on social media, are often intended to have only momentary relevance (Ursic 2016). The reasons and manner for which data is re-used in the future are unknown. George Washington was likely unaware that his dentures would be out on display for all to see at the Mount Vernon Museum in Virginia, over 200 years after his death. The specific meanings and intentions attached to historic data should be observed for what may be missing (Craig 2002, Ursic 2016, Kitchin 2014). 

Just as historical information can and has been used to contribute to current knowledge, awareness of the atmosphere in which data was produced can add important meaning (Craig 2002). 

"Meta-data are the information necessary to understand and effectively use data, including documentation of the data set contents, context, quality, structure and accessibility"(Michener 2006 p). 

The only hope for long term and scalable use of data, no matter the size is to place importance on creating well-documented and securely archived data. 

As data is deposited into repositories, for reuse and potentially long-term storage, those responsible for the data may be no longer be the originators and authors of that data (Wallis & Borgman 2011). If we extend these points about context into the future, imagine when enough time has passed to radically change the way that language is used. In such a situation, any use of language contained in a data set may potentially become misinterpreted or illegible to this new audience. 
When the original data creators are long gone, no persons responsible for the data will be available to revise the data. Then regarding those responsible for data, to what extent are they accountable for documenting meta data and data contexts for either newly generated data or re-used data? 

Personal items and information once only available to those in physical proximity to the deceased, are now also accompanied by traces of a person's activities across the internet. For many organisations, data are collected and deposited into closed ecosystems. Technology companies like Google, Facebook and Apple profit from reselling and sharing data produced by millions of users on their platforms (Ursic 2016). These companies play a role in both data authorship and ownership along with the users. The storing of data does not necessarily change the data ownership, if the human subject is considered a co-author or data owner. Yet, if those managing the data are in control of access and engagement with it (Clark et. al. 2011). Within management of this data and efforts to anonymise and de-identify, the human subjects have more or less relinquished ownership (Clark et. al. 2015). Then, who has the authority to release the data and when are data to be released, if ever? Furthermore, do we each have a right to retrieve our personal public data or is that data considered part of the public domain and digital commons, as a legal "fact" and historical document? Should these data resources remain appart from the common domain, there is also the possibility that a distinction may be made between the "information-rich" and the "information-poor" (Floridi 2006).

Sometimes the destruction of data has been intentional for the purposes of protecting the privacy of study participants. Data may also be deleted by individuals when the data can no longer be relied upon as accurate or complete (Ursic 2016). Data repositories rely on the deposit of materials from the communities they serve, forming a chain of stakeholders from the data creator to the repository and data user (Wallis & Borgman 2011). With respect to human data ethics and sensitive data, the justification of deletion may be spurred by the responsibilities of the researchers to respect the wishes and privacy of the subjects of study after the purposes of the data have been fulfilled (Clark et. al. 2015). This justification implies consent, however when data is instead harvested passively from the public domain or where the subject's identity is not available or easily obtainable, it is possible for data to exist without the human subject's knowledge (Clark et. al. 2015). The new ways that data is retrieved further confound the positions of duty to privacy and ownership of data.

Whilst concerned with increasing the physical longevity of data storage media, we must also turn to the quality of data and the ways that data contexts, publications and documentation are stored. No assumptions should be made that data without such documentation will be self-explanatory or easily understood by new audiences. No matter how advanced and long-term computer memory becomes, human memory is still limited. Whether the data should remain or whether the data cannot continue its legacy into future generations are notoriously hard decisions to make. 
Before data can be preserved for reuse in the future, data quality control must be employed and efforts made to ensure the metadata and documentation are also preserved. The original purpose and origins of data aid the responsible reuse of data, otherwise there are ethical and practical implications for future studies. It is likely that the data that is preserved today will exist long after we perish and in this way, we have the advantage of shaping our history, how we are represented and how we add value to new generations. Yet, what will constitute valuable data cannot be known. Instead, if we are to accept that the data stored today is irreplaceable information, we must also accept that its donation has high value. Framing data sets responsibly and ensuring respect and justice for human subjects are important steps to preserving a responsible data legacy.

#### References
Bates, J. (2016) Towards a critical data science - the complicated relationship between data and the democratic project, last viewed 10 Nov 2016, http://blogs.lse.ac.uk/impactofsocialsciences/2016/01/12/towards-a-critical-data-science-data-and-the-democratic-project/
Bowker, G.C. (2000) Biodiversity Datadiversity, Social Studies of Science, SAGE Publications Ltd; 30(5) 643-683 
Clark, K., Duckham, M., Guillemin, M., Hunter, A., McVernon, J., O'Keefe, C., Pitkin, C., Prawer, S., Sinnott, R., Warr, D., and Waycott, J. (2015) Guidelines for the Ethical Use of Digital Data in Human Research: Part B, last viewed 11 Nov 2017, https://www.carltonconnect.com.au/wp-content/uploads/2015/06/Ethical-Use-of-Digital-Data.pdf
Craig, E., (2002) Philosophy: A Very Short Introduction, Oxford University Press, pp. 684-822 & pp. 822-1051
Dykes, B. (2017) Why Companies Must Close The Data Literacy Divide, last viewed 6 Nov 2017, https://www.forbes.com/sites/brentdykes/2017/03/09/why-companies-must-close-the-data-literacy-divide/#6c580d8a369d
Floridi, L. (2006), Peering into the Future of the Infosphere, last viewed 10 Nov 2016, http://tidbits.com/article/8686
Kitchin, R. (2014) The Data Revolution: big data, open data, data infrastructures & their consequences., Sage Publications Inc., London
Leahey, E. (2008) Overseeing Research Practice: The Case of Data Editing, Science, Technology & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 620 
Michener, William K., and Brunt, James W., eds. (2009) Ecological Data: Design, Management and Processing, Hoboken, GB: Wiley-Blackwell, p92-100
Norton, A.T. (2017) Foreskin and the molecular politics of risk, Social Studies of Science, SAGE Publications Inc., vol. 47, no. 5, pp. 655-680 
Redman, T.C. (2013), Chapter 1: Data Quality Management Past, Present, and Future: Towards a Management System for Data, Handbook of data quality: research and practice. Springer, New York.
Schmidt, F. & Hunter, J. (2015) Methods of meta-analysis, Availability bias, source bias, and publication bias in meta-analysis, SAGE Publications Ltd., London, pp. 513-551
Service, R. (2017) DNA could store all of the world's data in one room, last viewed 10 Nov 2017, http://www.sciencemag.org/news/2017/03/dna-could-store-all-worlds-data-one-room
Song, Y., Zhu, D. (2009) Preface, High Density Data Storage - Principle, Technology, and Materials, World Scientific. Online version last viewed 10 Nov 2017, http://app.knovel.com/hotlink/toc/id:kpHDDSPTM3/high-density-data-
Thorp, J. (2016) Turning Data Around, last viewed 10 Nov 2017, https://medium.com/memo-random/turning-data-around-7acea1f7479c
Wallis, J. C. & Borgman, C. L. (2011). Who is responsible for data? An exploratory study of data authorship, ownership, and responsibility. Proceedings of the American Society for Information Science and Technology, vol. 48, no. 1, pp. 1-10.
Zimmerman, A. S. (2008) New Knowledge from Old Data: The Role of Standards in the Sharing and Reuse of Ecological Data, Science, Technology, & Human Values, SAGE Publications Inc., vol. 33, no. 5, pp. 631-652

## Herry

## Passiona

## Rory

## Tracy
